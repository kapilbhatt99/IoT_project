{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import Circle\n",
    "from google.colab.patches import cv2_imshow\n",
    "import dlib\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "weights = '/content/drive/My Drive/ML project/MODELS/mmod_human_face_detector.dat'\n",
    "# initializing cnn face detector model\n",
    "cnn_face_detector = dlib.cnn_face_detection_model_v1(weights)\n",
    "# Get Face Detector from dlib\n",
    "# This allows us to detect faces in images\n",
    "# face_detector = dlib.get_frontal_face_detector()\n",
    "# Get Pose Predictor from dlib\n",
    "# This allows us to detect landmark points in faces and understand the pose/angle of the face\n",
    "shape_predictor = dlib.shape_predictor('/content/drive/My Drive/ML project/MODELS/shape_predictor_68_face_landmarks.dat')\n",
    "# Get the face recognition model\n",
    "# This is what gives us the face encodings (numbers that identify the face of a particular person)\n",
    "face_recognition_model = dlib.face_recognition_model_v1('/content/drive/My Drive/ML project/MODELS/dlib_face_recognition_resnet_model_v1.dat')\n",
    "# This is the tolerance for face comparisons\n",
    "# The lower the number - the stricter the comparison\n",
    "# To avoid false matches, use lower value\n",
    "# To avoid false negatives (i.e. faces of the same person doesn't match), use higher value\n",
    "# 0.5-0.6 works well\n",
    "TOLERANCE = 0.50\n",
    "\n",
    "def rect_to_bb(face):\n",
    "    # take a bounding predicted by dlib and convert it\n",
    "    # to the format (x, y, w, h) as we would normally do\n",
    "    # with OpenCV\n",
    "    x = face.rect.left()\n",
    "    y = face.rect.top()\n",
    "    w = face.rect.right() - x\n",
    "    h = face.rect.bottom() - y\n",
    "    return (x, y, w, h)\n",
    "\n",
    "# This function will take an image and return its face encodings using the neural network\n",
    "def get_face_encodings(path_to_image):\n",
    "    # Load image using scipy\n",
    "    # print(path_to_image)\n",
    "    image = cv2.imread(path_to_image)\n",
    "    # Detect faces using the face detector\n",
    "    # detected_faces = face_detector(image, 1)\n",
    "    res = cnn_face_detector(image,1)\n",
    "    # detected_faces.rect = detected_faces\n",
    "    shapes_faces = []\n",
    "    for r in res:\n",
    "        face = r.rect\n",
    "        # print(face)\n",
    "        # Get pose/landmarks of those faces\n",
    "        # Will be used as an input to the function that computes face encodings\n",
    "        # This allows the neural network to be able to produce similar numbers for faces of the same people, regardless of camera angle and/or face positioning in the image\n",
    "        shapes_faces.append(shape_predictor(image, face))\n",
    "    # For every face detected, compute the face encodings\n",
    "    return [np.array(face_recognition_model.compute_face_descriptor(image, face_pose, 1)) for face_pose in shapes_faces]\n",
    "\n",
    "def get_vid_encodings(v_image,face):\n",
    "    # print(face)\n",
    "    # detected_faces = face_detector(v_image, 1)\n",
    "    # Get pose/landmarks of those faces\n",
    "    # Will be used as an input to the function that computes face encodings\n",
    "    # This allows the neural network to be able to produce similar numbers for faces of the same people, regardless of camera angle and/or face positioning in the image\n",
    "    shapes_faces = shape_predictor(v_image, face)\n",
    "    # For every face detected, compute the face encodings\n",
    "    # return [np.array(face_recognition_model.compute_face_descriptor(v_image, face_pose, 1)) for face_pose in shapes_faces]\n",
    "    return [np.array(face_recognition_model.compute_face_descriptor(v_image, shapes_faces, 1))]\n",
    "\n",
    "# This function takes a list of known faces\n",
    "def compare_face_encodings(known_faces, face):\n",
    "    # Finds the difference between each known face and the given face (that we are comparing)\n",
    "    # Calculate norm for the differences with each known face\n",
    "    # Return an array with True/Face values based on whether or not a known face matched with the given face\n",
    "    print(type(face))\n",
    "    print(type(known_faces))\n",
    "    # print(known_faces)\n",
    "    # A match occurs when the (norm) difference between a known face and the given face is less than or equal to the TOLERANCE value\n",
    "    return (np.linalg.norm(known_faces - face, axis=1) <= TOLERANCE)\n",
    "\n",
    "# This function returns the name of the person whose image matches with the given face (or 'Not Found')\n",
    "# known_faces is a list of face encodings\n",
    "# names is a list of the names of people (in the same order as the face encodings - to match the name with an encoding)\n",
    "# face is the face we are looking for\n",
    "def find_match(known_faces, names, face):\n",
    "    # Call compare_face_encodings to get a list of True/False values indicating whether or not there's a match\n",
    "    matches = compare_face_encodings(known_faces, face)\n",
    "    # Return the name of the first match\n",
    "    count = 0\n",
    "    for match in matches:\n",
    "        if match:\n",
    "            return names[count]\n",
    "        count += 1\n",
    "    # Return not found if no match found\n",
    "    return 'Not Found'\n",
    "\n",
    "# Get path to all the known images\n",
    "# Filtering on .jpg extension - so this will only work with JPEG images ending with .jpg\n",
    "image_filenames = filter(lambda x: x.endswith('.jpg'), os.listdir('/content/drive/My Drive/ML project/known faces/'))\n",
    "# Sort in alphabetical order\n",
    "image_filenames = sorted(image_filenames)\n",
    "# Get full paths to images\n",
    "paths_to_images = ['/content/drive/My Drive/ML project/known faces/' + x for x in image_filenames]\n",
    "# List of face encodings we have\n",
    "face_encodings = []\n",
    "# Loop over images to get the encoding one by one\n",
    "start = time.time()\n",
    "\n",
    "for path_to_image in paths_to_images:\n",
    "    # Get face encodings from the image\n",
    "    face_encodings_in_image = get_face_encodings(path_to_image)\n",
    "    # Make sure there's exactly one face in the image\n",
    "    if len(face_encodings_in_image) != 1:\n",
    "        print(\"Please change image: \" + path_to_image + \" - it has \" + str(len(face_encodings_in_image)) + \" faces; it can only have one\")\n",
    "        exit()\n",
    "    # Append the face encoding found in that image to the list of face encodings we have\n",
    "    face_encodings.append(face_encodings_in_image[0])\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution Time for Encoding: {}\".format(end-start))\n",
    "\n",
    "# Get path to all the test images\n",
    "# Filtering on .jpg extension - so this will only work with JPEG images ending with .jpg\n",
    "test_filenames = filter(lambda x: x.endswith('.jpg'), os.listdir('/content/drive/My Drive/ML project/test/'))\n",
    "# Get full paths to test images\n",
    "paths_to_test_images = ['/content/drive/My Drive/ML project/test/' + x for x in test_filenames]\n",
    "# Get list of names of people by eliminating the .JPG OR .PNG extension from image filenames\n",
    "names = [x[:-4] for x in image_filenames]\n",
    "\n",
    "\n",
    "def draw_border(img, pt1, pt2, color, thickness, r, d):\n",
    "    x1,y1 = pt1\n",
    "    x2,y2 = pt2\n",
    " \n",
    "    # Top left\n",
    "    cv2.line(img, (x1 + r, y1), (x1 + r + d, y1), color, thickness)\n",
    "    cv2.line(img, (x1, y1 + r), (x1, y1 + r + d), color, thickness)\n",
    "    cv2.ellipse(img, (x1 + r, y1 + r), (r, r), 180, 0, 90, color, thickness)\n",
    " \n",
    "    # Top right\n",
    "    cv2.line(img, (x2 - r, y1), (x2 - r - d, y1), color, thickness)\n",
    "    cv2.line(img, (x2, y1 + r), (x2, y1 + r + d), color, thickness)\n",
    "    cv2.ellipse(img, (x2 - r, y1 + r), (r, r), 270, 0, 90, color, thickness)\n",
    " \n",
    "    # Bottom left\n",
    "    cv2.line(img, (x1 + r, y2), (x1 + r + d, y2), color, thickness)\n",
    "    cv2.line(img, (x1, y2 - r), (x1, y2 - r - d), color, thickness)\n",
    "    cv2.ellipse(img, (x1 + r, y2 - r), (r, r), 90, 0, 90, color, thickness)\n",
    " \n",
    "    # Bottom right\n",
    "    cv2.line(img, (x2 - r, y2), (x2 - r - d, y2), color, thickness)\n",
    "    cv2.line(img, (x2, y2 - r), (x2, y2 - r - d), color, thickness)\n",
    "    cv2.ellipse(img, (x2 - r, y2 - r), (r, r), 0, 0, 90, color, thickness)\n",
    "\n",
    "# draw each face separately\n",
    "def draw_faces_cnn(data):\n",
    "    # load the image\n",
    "    # data = pyplot.imread(filename)\n",
    "    # data = imagefile\n",
    "    # load image from file\n",
    "    # create the detector, using default weights\n",
    "    # detector = MTCNN()\n",
    "    # detect faces in the image\n",
    "    # result_list = detector.detect_faces(data)\n",
    "    # result_list = face_detector(data, 1)\n",
    "    result_list = cnn_face_detector(data, 1)\n",
    "    # print(result_list)\n",
    "    # display faces on the original image\n",
    "    # plot each face as a subplot\n",
    "    for i in range(len(result_list)):\n",
    "        # get coordinates\n",
    "        # x1, y1, width, height = result_list[i]['box']\n",
    "        x1, y1, width, height = rect_to_bb(result_list[i])\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        draw_border(data, (x1, y1), (x2, y2), (0, 255, 0),4, 15, 10)\n",
    "        image = data[y1-40:y2+40, x1-40:x2+40]\n",
    "        res = result_list[i].rect\n",
    "        cv2_imshow(image)\n",
    "        # flag = check_faces_cnn(image,i)\n",
    "        # res = face_detector(image, 1)\n",
    "        # print(flag)\n",
    "        flag = True # if len(res)==1 else False\n",
    "        if flag==True:\n",
    "            print(\"Face Detected\")\n",
    "            # (h,w) = image.shape[:2]\n",
    "            # center = (w/2,h/2)\n",
    "            # M = cv2.getRotationMatrix2D(center,270,1.0)\n",
    "            # rotated270 = cv2.warpAffine(image,M,(h,w))\n",
    "            # face_encodings_in_image = get_vid_encodings(rotated270)\n",
    "            face_encodings_in_image = get_vid_encodings(data,res)\n",
    "            if len(face_encodings_in_image) != 1:\n",
    "                print(\"Please change image: - it has \" + str(len(face_encodings_in_image)) + \" faces; it can only have one\")\n",
    "                continue\n",
    "            # Find match for the face encoding found in this test image\n",
    "            match = find_match(face_encodings, names, face_encodings_in_image[0])\n",
    "            # match = find_match(face_encodings, names, face_encodings_in_image[0])\n",
    "            # Print the path of test image and the corresponding match\n",
    "            # \" + path_to_image + \"\n",
    "            print(\"This is\",match)\n",
    "        else:\n",
    "            print(\"No Face\")\n",
    "            continue\n",
    "\n",
    "new_image_filenames = filter(lambda x: x.endswith('.jpg') or x.endswith('.png'), os.listdir('/content/drive/My Drive/ML project/test/'))\n",
    "# Sort in alphabetical order\n",
    "new_image_filenames = sorted(new_image_filenames)\n",
    "# Get full paths to images\n",
    "#paths_to_new_images = ['/content/drive/My Drive/ML project/test/' + x for x in new_image_filenames]\n",
    "paths_to_new_images = [\n",
    "                       # 'h2.jpg'\n",
    "                       '/content/drive/My Drive/ML project/known faces/Hritik Roshan.jpg',\n",
    "                       '/content/drive/My Drive/ML project/known faces/Yashvi Raythatha.jpg',\n",
    "                       '/content/drive/My Drive/ML project/test/bean.jpg',\n",
    "                       #'img1.jpg'\n",
    "                       ]\n",
    "start = time.time()\n",
    "for x in paths_to_new_images:\n",
    "    img = cv2.imread(x)\n",
    "    print(x)\n",
    "    cv2_imshow(img)\n",
    "    # img1 = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    # cv2_imshow(img1)\n",
    "    # img1[...,2]=50\n",
    "    # cv2_imshow(img1)\n",
    "    # img2 = cv2.cvtColor(img1, cv2.COLOR_HSV2BGR)\n",
    "    # cv2_imshow(img)\n",
    "    # cv2_imshow(img2)\n",
    "    draw_faces_cnn(img)\n",
    "    # draw_faces_cnn(img1)\n",
    "    # draw_faces_cnn(img2)\n",
    "end = time.time()\n",
    "print(\"Recognition time {}\".format(end - start))\n",
    "cv2.destroyAllWindows()\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
